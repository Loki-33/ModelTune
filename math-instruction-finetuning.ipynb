{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13500691,"sourceType":"datasetVersion","datasetId":8572047},{"sourceId":619322,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":465804,"modelId":481629}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade transformers huggingface_hub --q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch \nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom accelerate import Accelerator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T19:30:11.125847Z","iopub.execute_input":"2025-10-25T19:30:11.126092Z","iopub.status.idle":"2025-10-25T19:30:23.139622Z","shell.execute_reply.started":"2025-10-25T19:30:11.126063Z","shell.execute_reply":"2025-10-25T19:30:23.138793Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"model_name=\"EleutherAI/pythia-410m\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:30:52.986799Z","iopub.execute_input":"2025-10-24T06:30:52.987076Z","iopub.status.idle":"2025-10-24T06:30:52.990940Z","shell.execute_reply.started":"2025-10-24T06:30:52.987052Z","shell.execute_reply":"2025-10-24T06:30:52.990120Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"accelerator = Accelerator(gradient_accumulation_steps=4,\n                         mixed_precision='fp16')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:30:54.034059Z","iopub.execute_input":"2025-10-24T06:30:54.034807Z","iopub.status.idle":"2025-10-24T06:30:54.151375Z","shell.execute_reply.started":"2025-10-24T06:30:54.034782Z","shell.execute_reply":"2025-10-24T06:30:54.150697Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"accelerator.num_processes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:30:55.913932Z","iopub.execute_input":"2025-10-24T06:30:55.914501Z","iopub.status.idle":"2025-10-24T06:30:55.920108Z","shell.execute_reply.started":"2025-10-24T06:30:55.914473Z","shell.execute_reply":"2025-10-24T06:30:55.919216Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name,attn_implementation=\"sdpa\",dtype=torch.float16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:30:57.096495Z","iopub.execute_input":"2025-10-24T06:30:57.097007Z","iopub.status.idle":"2025-10-24T06:31:17.549035Z","shell.execute_reply.started":"2025-10-24T06:30:57.096977Z","shell.execute_reply":"2025-10-24T06:31:17.548443Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db5644af4ffb49a7996799c38ddd1136"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8930e2445d1f40b6ac95a0de182899af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f685033246a44fe4b2c236d35f328735"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"748584b09a734b339aa52d7b55cf2e84"}},"metadata":{}},{"name":"stderr","text":"2025-10-24 06:31:00.495019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761287460.738093      87 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761287460.808235      87 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/911M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba6d0eb9b51646a48e4a0c762d205e07"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"model.gradient_checkpointing_enable()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:17.550188Z","iopub.execute_input":"2025-10-24T06:31:17.550687Z","iopub.status.idle":"2025-10-24T06:31:17.555649Z","shell.execute_reply.started":"2025-10-24T06:31:17.550667Z","shell.execute_reply":"2025-10-24T06:31:17.554912Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from peft import LoraConfig, TaskType, get_peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:17.556405Z","iopub.execute_input":"2025-10-24T06:31:17.556761Z","iopub.status.idle":"2025-10-24T06:31:18.039982Z","shell.execute_reply.started":"2025-10-24T06:31:17.556726Z","shell.execute_reply":"2025-10-24T06:31:18.039381Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"config = LoraConfig(\n        r=8,\n        lora_alpha=16,\n        lora_dropout=0.1,\n        bias='none',\n        target_modules=[\"query_key_value\"],\n        task_type=TaskType.CAUSAL_LM\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:18.041255Z","iopub.execute_input":"2025-10-24T06:31:18.041600Z","iopub.status.idle":"2025-10-24T06:31:18.045362Z","shell.execute_reply.started":"2025-10-24T06:31:18.041579Z","shell.execute_reply":"2025-10-24T06:31:18.044686Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"lora_model = get_peft_model(model, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:20.625231Z","iopub.execute_input":"2025-10-24T06:31:20.625496Z","iopub.status.idle":"2025-10-24T06:31:20.679784Z","shell.execute_reply.started":"2025-10-24T06:31:20.625478Z","shell.execute_reply":"2025-10-24T06:31:20.679190Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(lora_model.print_trainable_parameters())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:23.210533Z","iopub.execute_input":"2025-10-24T06:31:23.211025Z","iopub.status.idle":"2025-10-24T06:31:23.217120Z","shell.execute_reply.started":"2025-10-24T06:31:23.210999Z","shell.execute_reply":"2025-10-24T06:31:23.216337Z"}},"outputs":[{"name":"stdout","text":"trainable params: 786,432 || all params: 406,120,448 || trainable%: 0.1936\nNone\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\nlora_model.config.pad_token_id = tokenizer.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:25.004614Z","iopub.execute_input":"2025-10-24T06:31:25.005354Z","iopub.status.idle":"2025-10-24T06:31:25.009932Z","shell.execute_reply.started":"2025-10-24T06:31:25.005308Z","shell.execute_reply":"2025-10-24T06:31:25.008866Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def generate(text, max_tokens=100):\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    tokens = lora_model.generate(**inputs, max_new_tokens=max_tokens)\n    return tokenizer.decode(tokens[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:25.882810Z","iopub.execute_input":"2025-10-24T06:31:25.883319Z","iopub.status.idle":"2025-10-24T06:31:25.889797Z","shell.execute_reply.started":"2025-10-24T06:31:25.883280Z","shell.execute_reply":"2025-10-24T06:31:25.888918Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"generate(\"How can we reduce air pollution?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:27.740581Z","iopub.execute_input":"2025-10-24T06:31:27.741284Z","iopub.status.idle":"2025-10-24T06:31:40.986880Z","shell.execute_reply.started":"2025-10-24T06:31:27.741244Z","shell.execute_reply":"2025-10-24T06:31:40.985883Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'How can we reduce air pollution?\\n\\nThe answer is simple: we need to reduce the amount of carbon dioxide in the atmosphere.\\n\\nThe problem is that the amount of carbon dioxide in the atmosphere is increasing.\\n\\nThe amount of carbon dioxide in the atmosphere is increasing because of the burning of fossil fuels.\\n\\nThe burning of fossil fuels is causing the amount of carbon dioxide in the atmosphere to increase.\\n\\nThe amount of carbon dioxide in the atmosphere is increasing because of the burning of fossil fuels.\\n\\nThe'"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"print(generate(\"Write a python code for adding two integers\", max_tokens=50))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:40.988436Z","iopub.execute_input":"2025-10-24T06:31:40.988832Z","iopub.status.idle":"2025-10-24T06:31:45.851622Z","shell.execute_reply.started":"2025-10-24T06:31:40.988801Z","shell.execute_reply":"2025-10-24T06:31:45.850589Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Write a python code for adding two integers to a list.\n\nA:\n\nYou can use the built-in list comprehension:\n>>> [int(x) for x in [1, 2, 3]]\n[1, 2, 3]\n\nA:\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(generate(\"What is 2+1 equals to?\", max_tokens=10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:45.852672Z","iopub.execute_input":"2025-10-24T06:31:45.853136Z","iopub.status.idle":"2025-10-24T06:31:47.065881Z","shell.execute_reply.started":"2025-10-24T06:31:45.853105Z","shell.execute_reply":"2025-10-24T06:31:47.064863Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What is 2+1 equals to?\n-1\nLet x = -0.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from datasets import load_dataset\ndataset =load_dataset('tatsu-lab/alpaca', split='train')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:47.067616Z","iopub.execute_input":"2025-10-24T06:31:47.067942Z","iopub.status.idle":"2025-10-24T06:31:49.736533Z","shell.execute_reply.started":"2025-10-24T06:31:47.067914Z","shell.execute_reply":"2025-10-24T06:31:49.735759Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8d02e84f824aa58d6945ac001b18a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001-a09b74b3ef9c3b(…):   0%|          | 0.00/24.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4da1ba5df7d4679bf0fefa2a1dacad4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5d7c7ea4aa140a2b4da82c7e070b62f"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"def create_dataset(dataset):\n    prompts = []\n    responses = []\n    for data in dataset:\n        data_split = data['text'].split('### Response:\\n', 1)\n        prompt = data_split[0] + '### Response:\\n'\n        response = data_split[1].strip()\n        if response:\n            prompts.append(prompt)\n            responses.append(response)\n    return {\n        'prompts': prompts,\n        'responses': responses\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:52.201817Z","iopub.execute_input":"2025-10-24T06:31:52.202467Z","iopub.status.idle":"2025-10-24T06:31:52.207897Z","shell.execute_reply.started":"2025-10-24T06:31:52.202440Z","shell.execute_reply":"2025-10-24T06:31:52.207017Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"datas = create_dataset(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:53.466219Z","iopub.execute_input":"2025-10-24T06:31:53.466522Z","iopub.status.idle":"2025-10-24T06:31:55.439303Z","shell.execute_reply.started":"2025-10-24T06:31:53.466499Z","shell.execute_reply":"2025-10-24T06:31:55.438428Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:56.723685Z","iopub.execute_input":"2025-10-24T06:31:56.723961Z","iopub.status.idle":"2025-10-24T06:31:56.727995Z","shell.execute_reply.started":"2025-10-24T06:31:56.723939Z","shell.execute_reply":"2025-10-24T06:31:56.727194Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class InstructionDataset(Dataset):\n    def __init__(self, data):\n        self.prompts = data['prompts']\n        self.responses = data['responses']\n    \n    def __len__(self):\n        return len(self.prompts)\n    \n    def __getitem__(self, idx):\n        return {\n            'prompt': self.prompts[idx],\n            'response': self.responses[idx]\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:57.922030Z","iopub.execute_input":"2025-10-24T06:31:57.922428Z","iopub.status.idle":"2025-10-24T06:31:57.928703Z","shell.execute_reply.started":"2025-10-24T06:31:57.922394Z","shell.execute_reply":"2025-10-24T06:31:57.927827Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"instruction_dataset = InstructionDataset(datas)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:59.018756Z","iopub.execute_input":"2025-10-24T06:31:59.019041Z","iopub.status.idle":"2025-10-24T06:31:59.023070Z","shell.execute_reply.started":"2025-10-24T06:31:59.019018Z","shell.execute_reply":"2025-10-24T06:31:59.022125Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class DataCollator:\n    def __init__(self, tokenizer):\n        self.tokenizer=tokenizer\n\n    def __call__(self, examples):\n        texts = [exa['prompt']+exa['response'] for exa in examples]\n        tokenized = self.tokenizer(\n            texts, \n            padding=True, \n            max_length=256,\n            return_tensors='pt',\n            truncation=True\n        )\n        labels = tokenized['input_ids'].clone()\n        labels[labels == tokenizer.pad_token_id] = -100\n\n        return {\n            'input_ids':tokenized['input_ids'],\n            'attention_mask': tokenized['attention_mask'],\n            'labels': labels\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:31:59.892279Z","iopub.execute_input":"2025-10-24T06:31:59.892562Z","iopub.status.idle":"2025-10-24T06:31:59.898261Z","shell.execute_reply.started":"2025-10-24T06:31:59.892541Z","shell.execute_reply":"2025-10-24T06:31:59.897332Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"data_collator = DataCollator(tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:32:01.234164Z","iopub.execute_input":"2025-10-24T06:32:01.234461Z","iopub.status.idle":"2025-10-24T06:32:01.238694Z","shell.execute_reply.started":"2025-10-24T06:32:01.234438Z","shell.execute_reply":"2025-10-24T06:32:01.237781Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"dataloader = DataLoader(instruction_dataset, batch_size=16, collate_fn=data_collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:32:12.627681Z","iopub.execute_input":"2025-10-24T06:32:12.628466Z","iopub.status.idle":"2025-10-24T06:32:12.632930Z","shell.execute_reply.started":"2025-10-24T06:32:12.628434Z","shell.execute_reply":"2025-10-24T06:32:12.631937Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(lora_model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:32:13.622398Z","iopub.execute_input":"2025-10-24T06:32:13.622687Z","iopub.status.idle":"2025-10-24T06:32:13.628612Z","shell.execute_reply.started":"2025-10-24T06:32:13.622665Z","shell.execute_reply":"2025-10-24T06:32:13.627593Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"lora_model, optimizer, dataloader = accelerator.prepare(lora_model, optimizer, dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:32:14.498023Z","iopub.execute_input":"2025-10-24T06:32:14.498822Z","iopub.status.idle":"2025-10-24T06:32:14.969118Z","shell.execute_reply.started":"2025-10-24T06:32:14.498795Z","shell.execute_reply":"2025-10-24T06:32:14.968194Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:32:15.474592Z","iopub.execute_input":"2025-10-24T06:32:15.475392Z","iopub.status.idle":"2025-10-24T06:32:15.480006Z","shell.execute_reply.started":"2025-10-24T06:32:15.475355Z","shell.execute_reply":"2025-10-24T06:32:15.478983Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"print(f\"{torch.cuda.memory_allocated()/1e9:.2f} Gb's\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:32:16.498294Z","iopub.execute_input":"2025-10-24T06:32:16.499081Z","iopub.status.idle":"2025-10-24T06:32:16.503427Z","shell.execute_reply.started":"2025-10-24T06:32:16.499054Z","shell.execute_reply":"2025-10-24T06:32:16.502532Z"}},"outputs":[{"name":"stdout","text":"0.81 Gb's\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import os\nos.makedirs('/kaggle/working/checkpoints', exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:32:18.178000Z","iopub.execute_input":"2025-10-24T06:32:18.178304Z","iopub.status.idle":"2025-10-24T06:32:18.182392Z","shell.execute_reply.started":"2025-10-24T06:32:18.178279Z","shell.execute_reply":"2025-10-24T06:32:18.181493Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"lora_model.train()\nbest_loss = float('inf')\nfor epoch in range(10):\n    total_loss = 0\n    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}')\n    for i, d in enumerate(progress_bar):\n        #print(f\"Before forward - Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n        with accelerator.accumulate(lora_model):\n            optimizer.zero_grad(set_to_none=True)\n            output = lora_model(input_ids=d['input_ids'],\n                               attention_mask=d['attention_mask'],\n                               labels=d['labels'])\n            #print(f\"After forward - Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n            loss = output.loss\n            accelerator.backward(loss)\n            #print(f\"After backward - Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n            if accelerator.sync_gradients:\n                accelerator.clip_grad_norm_(lora_model.parameters(), max_norm=1.0)\n            optimizer.step()\n            #print(f\"After optimizer step - Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n            loss_val = loss.detach().item()\n            total_loss += loss_val\n            progress_bar.set_postfix({'loss': loss_val})\n            del output, loss\n            #print(f\"After cleanup - Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\\n\")\n    avg_loss = total_loss/len(dataloader)\n    print(f\"[+] Epoch: {epoch+1} completed, Avg Loss: {avg_loss:.4f}\")\n    try:\n        if (epoch + 1) % 2 == 0:\n            accelerator.save_state(f\"/kaggle/working/checkpoints/epoch_{epoch+1}\")\n    \n        if avg_loss < best_loss:\n            best_loss = avg_loss\n            accelerator.save_state(\"/kaggle/working/checkpoints/best_model\")\n            print(f\"[*] New best model saved! Loss: {best_loss:.4f}\")\n    except Exception as e:\n        print(f\"[!] Failed to save: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T06:32:45.096530Z","iopub.execute_input":"2025-10-24T06:32:45.097437Z","iopub.status.idle":"2025-10-24T12:28:48.134641Z","shell.execute_reply.started":"2025-10-24T06:32:45.097399Z","shell.execute_reply":"2025-10-24T12:28:48.133744Z"}},"outputs":[{"name":"stderr","text":"Epoch 1:   0%|          | 0/3249 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\nEpoch 1: 100%|██████████| 3249/3249 [35:15<00:00,  1.54it/s, loss=1.7] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 1 completed, Avg Loss: 1.4304\n[*] New best model saved! Loss: 1.4304\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 3249/3249 [35:31<00:00,  1.52it/s, loss=1.67] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 2 completed, Avg Loss: 1.3495\n[*] New best model saved! Loss: 1.3495\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 3249/3249 [35:32<00:00,  1.52it/s, loss=1.63] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 3 completed, Avg Loss: 1.3345\n[*] New best model saved! Loss: 1.3345\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 3249/3249 [35:32<00:00,  1.52it/s, loss=1.61] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 4 completed, Avg Loss: 1.3252\n[*] New best model saved! Loss: 1.3252\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 3249/3249 [35:32<00:00,  1.52it/s, loss=1.59] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 5 completed, Avg Loss: 1.3189\n[*] New best model saved! Loss: 1.3189\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 3249/3249 [35:34<00:00,  1.52it/s, loss=1.56] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 6 completed, Avg Loss: 1.3144\n[*] New best model saved! Loss: 1.3144\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 3249/3249 [35:37<00:00,  1.52it/s, loss=1.53] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 7 completed, Avg Loss: 1.3110\n[*] New best model saved! Loss: 1.3110\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 3249/3249 [35:38<00:00,  1.52it/s, loss=1.51] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 8 completed, Avg Loss: 1.3087\n[*] New best model saved! Loss: 1.3087\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 3249/3249 [35:40<00:00,  1.52it/s, loss=1.49] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 9 completed, Avg Loss: 1.3070\n[*] New best model saved! Loss: 1.3070\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 3249/3249 [35:34<00:00,  1.52it/s, loss=1.46] \n","output_type":"stream"},{"name":"stdout","text":"[+] Epoch: 10 completed, Avg Loss: 1.3062\n[*] New best model saved! Loss: 1.3062\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"accelerator.unwrap_model(lora_model).save_pretrained(\"/kaggle/working/trained_sft_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:28:48.187796Z","iopub.status.idle":"2025-10-24T12:28:48.187996Z","shell.execute_reply.started":"2025-10-24T12:28:48.187896Z","shell.execute_reply":"2025-10-24T12:28:48.187905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.listdir('/kaggle/working/checkpoints/best_model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:31:39.811396Z","iopub.execute_input":"2025-10-24T12:31:39.811639Z","iopub.status.idle":"2025-10-24T12:31:39.816887Z","shell.execute_reply.started":"2025-10-24T12:31:39.811622Z","shell.execute_reply":"2025-10-24T12:31:39.816297Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"['model.safetensors', 'random_states_0.pkl', 'scaler.pt', 'optimizer.bin']"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"!zip -r /kaggle/working/best_model.zip /kaggle/working/checkpoints/best_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:32:51.100420Z","iopub.execute_input":"2025-10-24T12:32:51.100750Z","iopub.status.idle":"2025-10-24T12:33:29.319476Z","shell.execute_reply.started":"2025-10-24T12:32:51.100730Z","shell.execute_reply":"2025-10-24T12:33:29.318473Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/checkpoints/best_model/ (stored 0%)\n  adding: kaggle/working/checkpoints/best_model/model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 8%)\n  adding: kaggle/working/checkpoints/best_model/random_states_0.pkl (deflated 26%)\n  adding: kaggle/working/checkpoints/best_model/scaler.pt (deflated 60%)\n  adding: kaggle/working/checkpoints/best_model/optimizer.bin (deflated 7%)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"accelerator.load_state(\"/kaggle/working/checkpoints/best_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:37:26.521373Z","iopub.execute_input":"2025-10-24T12:37:26.521687Z","iopub.status.idle":"2025-10-24T12:37:26.911726Z","shell.execute_reply.started":"2025-10-24T12:37:26.521666Z","shell.execute_reply":"2025-10-24T12:37:26.911201Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def generate(model, text, max_tokens=100):\n    model.eval()\n    inputs = tokenizer(text, return_tensors=\"pt\").to(lora_model.device)\n    with torch.no_grad():\n        tokens = model.generate(**inputs, max_new_tokens=max_tokens,\n                               repetition_penalty=1.2, \n                               no_repeat_ngram_size=3)\n    return tokenizer.decode(tokens[0], skip_special_tokens=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T13:01:19.793548Z","iopub.execute_input":"2025-10-24T13:01:19.794126Z","iopub.status.idle":"2025-10-24T13:01:19.798622Z","shell.execute_reply.started":"2025-10-24T13:01:19.794101Z","shell.execute_reply":"2025-10-24T13:01:19.798026Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"print(generate(lora_model, 'What is 2+2=', max_tokens=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T13:01:22.927110Z","iopub.execute_input":"2025-10-24T13:01:22.927883Z","iopub.status.idle":"2025-10-24T13:01:23.033590Z","shell.execute_reply.started":"2025-10-24T13:01:22.927857Z","shell.execute_reply":"2025-10-24T13:01:23.033013Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What is 2+2=3?\n-\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"print(generate('write a 2 paragraph on love', max_tokens=100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T13:01:24.641368Z","iopub.execute_input":"2025-10-24T13:01:24.641636Z","iopub.status.idle":"2025-10-24T13:01:24.662753Z","shell.execute_reply.started":"2025-10-24T13:01:24.641616Z","shell.execute_reply":"2025-10-24T13:01:24.661666Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_87/132789323.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'write a 2 paragraph on love'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: generate() missing 1 required positional argument: 'text'"],"ename":"TypeError","evalue":"generate() missing 1 required positional argument: 'text'","output_type":"error"}],"execution_count":82},{"cell_type":"code","source":"prompts = [\n    \"### Instruction:\\nList 3 benefits of exercise.\\n\\n### Response:\\n\",\n    \"### Instruction:\\nExplain photosynthesis simply.\\n\\n### Response:\\n\",\n    \"### Instruction:\\nWrite a haiku about coding.\\n\\n### Response:\\n\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:44:40.817402Z","iopub.execute_input":"2025-10-24T12:44:40.817967Z","iopub.status.idle":"2025-10-24T12:44:40.821573Z","shell.execute_reply.started":"2025-10-24T12:44:40.817943Z","shell.execute_reply":"2025-10-24T12:44:40.820968Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"base_model = AutoModelForCausalLM.from_pretrained(model_name, dtype=torch.float16, device_map='cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:45:54.779427Z","iopub.execute_input":"2025-10-24T12:45:54.780240Z","iopub.status.idle":"2025-10-24T12:45:55.700321Z","shell.execute_reply.started":"2025-10-24T12:45:54.780206Z","shell.execute_reply":"2025-10-24T12:45:55.699626Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"def get_perplexity(model, text):\n    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n    with torch.no_grad():\n        outputs = model(**inputs, labels=inputs['input_ids'])\n        loss = outputs.loss\n    return torch.exp(loss).item()\n\ntest_text = \"### Instruction:\\nWhat is AI?\\n\\n### Response:\\nAI is artificial intelligence...\"\nprint(f\"Base perplexity: {get_perplexity(base_model, test_text)}\")\nprint(f\"Finetuned perplexity: {get_perplexity(lora_model, test_text)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T13:07:03.851448Z","iopub.execute_input":"2025-10-24T13:07:03.852037Z","iopub.status.idle":"2025-10-24T13:07:03.909128Z","shell.execute_reply.started":"2025-10-24T13:07:03.852015Z","shell.execute_reply":"2025-10-24T13:07:03.908495Z"}},"outputs":[{"name":"stdout","text":"Base perplexity: 58.5482063293457\nFinetuned perplexity: 50.240753173828125\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"print(generate(lora_model, '### Instruction:\\nWrite me a 3 line poem\\n\\n### Response:\\n'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:58:44.855091Z","iopub.execute_input":"2025-10-24T12:58:44.855386Z","iopub.status.idle":"2025-10-24T12:58:47.105584Z","shell.execute_reply.started":"2025-10-24T12:58:44.855367Z","shell.execute_reply":"2025-10-24T12:58:47.104908Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"### Instruction:\nWrite me a 3 line poem\n\n### Response:\nThe sun shone, the sky was blue and clear. \nA breeze blew through my hair, I felt so warm. \n  I wrote down this simple rhyme in my mind's eye. \n   It made sense to me, it seemed like such an easy thing. \n    And then as time passed by, I realized that I had done something special. \n     This is what life has given us - freedom from fear! \n      So let go of all your worries and take off\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"print(generate(lora_model, 'Say hello', max_tokens=10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T13:01:30.748518Z","iopub.execute_input":"2025-10-24T13:01:30.749106Z","iopub.status.idle":"2025-10-24T13:01:30.989260Z","shell.execute_reply.started":"2025-10-24T13:01:30.749081Z","shell.execute_reply":"2025-10-24T13:01:30.988700Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Say hello?\"\n\n\"Hello, how are you doing\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"print('gell')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}