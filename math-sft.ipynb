{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install --upgrade transformers huggingface_hub --q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os \nimport json \nfrom accelerate import Accelerator\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification\nfrom peft import LoraConfig, TaskType, get_peft_model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model = AutoModelForCausalLM.from_pretrained(model_name,attn_implementation=\"sdpa\",dtype=torch.float16, device_map='auto')\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\ntokenizer.padding_side = 'left'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from peft import PeftModel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/input/mathdataset/math_dataset.json\", 'r') as f:\n    dataset = json.load(f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\ntrain_data = []\nfor item in dataset['train']:\n    train_data.append({\n        'question': item['question'],\n        'answer': item['answer']\n    })\n\ntrain_dataset = Dataset.from_list(train_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collate_fn(batch):\n    text = [b['question']+b['answer'] for b in batch]\n    \n    \n    tokenized = tokenizer(text, \n                          truncation=True,\n                          max_length=128, padding=True,\n                          return_tensors='pt')\n\n    return {\n        'input_ids': tokenized['input_ids'],\n        'attention_mask': tokenized['attention_mask'],\n        'labels': tokenized['input_ids'].clone()\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accelerator = Accelerator(gradient_accumulation_steps=4,\n                         mixed_precision='fp16')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = PeftModel.from_pretrained(\n    base_model,\n    '/kaggle/input/loraadapters/pytorch/default/1',\n    trainable=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for n,p in model.named_parameters():\n    if 'lora' in n:\n        p.requires_grad=True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = optim.AdamW(model.parameters(), lr=1e-3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model, optimizer, dataloader = accelerator.prepare(model, optimizer, train_dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import PreTrainedModel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def sft_trainer(model: PeftModel|PreTrainedModel , \n                dataloader: DataLoader, \n                optimizer: optim.Optimizer, \n                num_epochs: int=10):\n    model.train()\n    best_loss = float('inf')\n    for epoch in range(num_epochs):\n        total_loss=0\n        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}')\n        for i, batch in enumerate(progress_bar):\n            with accelerator.accumulate(model):\n                optimizer.zero_grad()\n                output = model(input_ids=batch['input_ids'],\n                              attention_mask=batch['attention_mask'],\n                              labels=batch['labels'])\n                loss = output.loss\n                accelerator.backward(loss)\n                if accelerator.sync_gradients:\n                    accelerator.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                optimizer.step()\n                loss_val = loss.detach().item()\n                total_loss += loss_val\n                progress_bar.set_postfix({'loss': loss_val})\n                del output, loss\n        avg_loss = total_loss/len(dataloader)\n        print(f\"[+] Epoch: {epoch+1} completed, Avg Loss: {avg_loss:.4f}\")\n        try:        \n            if avg_loss < best_loss:\n                best_loss = avg_loss\n                accelerator.save_state(\"/kaggle/working/checkpoints/best_model\")\n                print(f\"[*] New best model saved! Loss: {best_loss:.4f}\")\n        except Exception as e:\n            print(f\"[!] Failed to save: {e}\")\n    return accelerator.unwrap_model(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sft_model = sft_trainer(\n    model,\n    dataloader, \n    optimizer,\n    num_epochs=50\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sft_model.save_pretrained('/kaggle/working/best_model')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputt = tokenizer('What is 1+2? ', return_tensors='pt')\nout= sft_model.generate(**inputt,max_new_tokens=2)\nprint(tokenizer.decode(out[0], skip_special_token=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}